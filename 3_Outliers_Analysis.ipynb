{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c93c9440",
   "metadata": {},
   "source": [
    "# Analyse the Influence of Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b66ec0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Models & Normalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting plotly plots to pdf \n",
    "import plotly.io as pio\n",
    "\n",
    "# Configuration: \n",
    "\n",
    "# Set to False for interactive zooming/hovering (Exploration)\n",
    "# Set to True for static images (PDF Export)\n",
    "EXPORT_MODE = True  \n",
    "\n",
    "if EXPORT_MODE:\n",
    "    # Forces all charts to be static images (requires 'pip install -U kaleido')\n",
    "    pio.renderers.default = \"png\" # Use \"png\" if svg gives you trouble\n",
    "    print(\"⚠️ EXPORT_MODE is ON. Charts will be static images.\")\n",
    "else:\n",
    "    # Default interactive plotly\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "    print(\"✅ Interactive mode. Charts will include zoom/hover.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753c1e41",
   "metadata": {},
   "source": [
    "## Open the clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a429b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Data/v0_cleaned_house_sales.csv\"\n",
    "\n",
    "df_clean = pd.read_csv(file_path)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19013351",
   "metadata": {},
   "source": [
    "## Analysing Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_clean.price)\n",
    "plt.title(\"Histogram: price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df_clean.price)\n",
    "plt.title(\"Boxplot: price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f318c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"price\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 houses over 4 million\n",
    "df_clean[df_clean.price > 4e6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5df39",
   "metadata": {},
   "source": [
    "## How much of the data is represented by outliers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc40113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_clean[\"price\"].sort_values()\n",
    "\n",
    "# Cumulative Quatiles\n",
    "fig = px.ecdf(df_sorted, x=\"price\", title=\"Cumulative Distribution of House Prices\")\n",
    "\n",
    "# Add a marker line at the 95th and 99th percentiles\n",
    "fig.add_hline(y=0.95, line_dash=\"dot\", annotation_text=\"95% of data\", annotation_position=\"bottom right\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e08e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantiles\n",
    "quantile_99 = df_clean.price.quantile(0.99)\n",
    "quantile_95 = df_clean.price.quantile(0.95)\n",
    "\n",
    "print(\"Quantile 99: \", quantile_99)\n",
    "print(\"Quantile 95: \", quantile_95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag the datapoints inside each quantiles 99 and 95\n",
    "df_clean[\"q_99\"] = (df_clean.price < quantile_99).astype(int)\n",
    "df_clean[\"q_95\"] = (df_clean.price < quantile_95).astype(int)\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57debd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The 99th quantile exclude {df_clean.shape[0] - df_clean.q_99.sum()} datapoints\")\n",
    "print(f\"The 95th quantile exclude {df_clean.shape[0] - df_clean.q_95.sum()} datapoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70484ee",
   "metadata": {},
   "source": [
    "## Sensitivity to outliers (metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d65d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "metrics_df = create_metrics_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff3a4aa",
   "metadata": {},
   "source": [
    "### Random Forest flagging the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "seed = 13\n",
    "# The price is the target variable\n",
    "y = df_clean[\"price\"]\n",
    "\n",
    "# All other variables are the features for the baseline model\n",
    "X = df_clean.drop([\"price\"], axis=1)\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common hyperparameters or the default ones\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor(random_state=seed)#default values + random_state = 13\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             rf_regressor,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             split = \"train\",\n",
    "                             comments=\"Outliers flagging, no normalization.\")\n",
    "\n",
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             rf_regressor,\n",
    "                             X_test,\n",
    "                             y_test,\n",
    "                             split = \"test\",\n",
    "                             comments=\"Outliers flagging, no normalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8eeacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad294b6",
   "metadata": {},
   "source": [
    "### Random Forest removing top 1% outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acbd65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "# The price is the target variable\n",
    "y = df_clean[df_clean.q_99 == 1][\"price\"]\n",
    "\n",
    "# All other variables are the features for the baseline model\n",
    "X = df_clean[df_clean.q_99 == 1].drop([\"price\", \"q_99\", \"q_95\"], axis=1)\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dbd222",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common hyperparameters or the default ones\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor(random_state=seed)#default values + random_state = 13\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             rf_regressor,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             split = \"train\",\n",
    "                             comments=\"Removing top 1%, no normalization.\")\n",
    "\n",
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             rf_regressor,\n",
    "                             X_test,\n",
    "                             y_test,\n",
    "                             split = \"test\",\n",
    "                             comments=\"Removing top 1%, no normalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497ada1",
   "metadata": {},
   "source": [
    "### Random Forest removing top 5% outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b68aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "# The price is the target variable\n",
    "y = df_clean[df_clean.q_95 == 1][\"price\"]\n",
    "\n",
    "# All other variables are the features for the baseline model\n",
    "X = df_clean[df_clean.q_95 == 1].drop([\"price\", \"q_99\", \"q_95\"], axis=1)\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7877a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b04867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common hyperparameters or the default ones\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor(random_state=seed)#default values + random_state = 13\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             rf_regressor,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             split = \"train\",\n",
    "                             comments=\"Removing top 5%, no normalization.\")\n",
    "\n",
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             rf_regressor,\n",
    "                             X_test,\n",
    "                             y_test,\n",
    "                             split = \"test\",\n",
    "                             comments=\"Removing top 5%, no normalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b8a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6676ac",
   "metadata": {},
   "source": [
    "### XGBoost flagging the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "seed = 13\n",
    "# The price is the target variable\n",
    "y = df_clean[\"price\"]\n",
    "\n",
    "# All other variables are the features for the baseline model\n",
    "X = df_clean.drop([\"price\"], axis=1)\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7806ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBRegressor(seed = seed)\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c969a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             xgb_clf,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             split = \"train\",\n",
    "                             comments=\"Outliers flagging, no normalization.\")\n",
    "\n",
    "\n",
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             xgb_clf,\n",
    "                             X_test,\n",
    "                             y_test,\n",
    "                             split = \"test\",\n",
    "                             comments=\"Outliers flagging, no normalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1db49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8e2c1",
   "metadata": {},
   "source": [
    "### XGBoost removing top 1% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "# The price is the target variable\n",
    "y = df_clean[df_clean.q_99 == 1][\"price\"]\n",
    "\n",
    "# All other variables are the features for the baseline model\n",
    "X = df_clean[df_clean.q_99 == 1].drop([\"price\", \"q_99\", \"q_95\"], axis=1)\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4565ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed40b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBRegressor(seed = seed)\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c74f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             xgb_clf,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             split = \"train\",\n",
    "                             comments=\"Removing top 1%, no normalization.\")\n",
    "\n",
    "\n",
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             xgb_clf,\n",
    "                             X_test,\n",
    "                             y_test,\n",
    "                             split = \"test\",\n",
    "                             comments=\"Removing top 1%, no normalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352b31f",
   "metadata": {},
   "source": [
    "### XGBoost removing top 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9dbcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "# The price is the target variable\n",
    "y = df_clean[df_clean.q_95 == 1][\"price\"]\n",
    "\n",
    "# All other variables are the features for the baseline model\n",
    "X = df_clean[df_clean.q_95 == 1].drop([\"price\", \"q_99\", \"q_95\"], axis=1)\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBRegressor(seed = seed)\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e344f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             xgb_clf,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             split = \"train\",\n",
    "                             comments=\"Removing top 5%, no normalization.\")\n",
    "\n",
    "\n",
    "metrics_df = add_new_metrics(metrics_df,\n",
    "                             xgb_clf,\n",
    "                             X_test,\n",
    "                             y_test,\n",
    "                             split = \"test\",\n",
    "                             comments=\"Removing top 5%, no normalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc64bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea703786",
   "metadata": {},
   "source": [
    "The feature flagging for both 99% and 95% worked better than removing the outliers, which means that the information about the top priced houses is still important\n",
    "to accurately predict the prices. In that sense, we will continue the analysis using the flagging of the columns instead of dropping them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc764d",
   "metadata": {},
   "source": [
    "# Data Leakage Analysis: Outlier Flagging\n",
    "\n",
    "Our initial approach calculated outlier thresholds using the entire dataset, introducing data leakage by allowing test set information to influence training features. While this is common in exploratory phases, it risks inflating model performance. In this section, we apply hypothesis testing to determine if correcting this leakage results in a statistically significant difference in model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply outlier flagging\n",
    "def apply_flagging(X, y):\n",
    "    # quantiles\n",
    "    quantile_99 = y.quantile(0.99)\n",
    "    quantile_95 = y.quantile(0.95)\n",
    "\n",
    "    print(\"Quantile 99: \", quantile_99)\n",
    "    print(\"Quantile 95: \", quantile_95)\n",
    "\n",
    "    # Flag the datapoints inside each quantiles 99 and 95\n",
    "    X[\"q_99\"] = (y < quantile_99).astype(int)\n",
    "    X[\"q_95\"] = (y < quantile_95).astype(int)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f31bf",
   "metadata": {},
   "source": [
    "## Preparing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "seed = 13\n",
    "# The price is the target variable\n",
    "y = df_clean[\"price\"]\n",
    "\n",
    "# All other variables are the features for the baseline model\n",
    "X = df_clean.drop([\"price\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47e252",
   "metadata": {},
   "source": [
    "### Dataset without Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56791e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data without leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Flagging\n",
    "X_train = apply_flagging(X_train, y_train)\n",
    "X_test = apply_flagging(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe128a7e",
   "metadata": {},
   "source": [
    "### Dataset with Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e6a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with leakage\n",
    "\n",
    "X_leakage = apply_flagging(X, y)\n",
    "\n",
    "X_train_leak, X_test_leak, y_train_leak, y_test_leak = train_test_split(X_leakage, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f77cf",
   "metadata": {},
   "source": [
    "### Experiment metrics df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New metrics dataframe\n",
    "\n",
    "leak_df = create_metrics_df()\n",
    "leak_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091121bd",
   "metadata": {},
   "source": [
    "## Statistical Significance Test: Random Forest Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521de71c",
   "metadata": {},
   "source": [
    "### Without leakage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common hyperparameters or the default ones\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor(random_state=seed)#default values + random_state = 13\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "leak_df = add_new_metrics(leak_df,\n",
    "                             rf_regressor,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             split = \"train\",\n",
    "                             comments=\"No leakage.\")\n",
    "\n",
    "leak_df = add_new_metrics(leak_df,\n",
    "                             rf_regressor,\n",
    "                             X_test,\n",
    "                             y_test,\n",
    "                             split = \"test\",\n",
    "                             comments=\"No leakage.\")\n",
    "\n",
    "leak_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb5722f",
   "metadata": {},
   "source": [
    "### With leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common hyperparameters or the default ones\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor_leak = RandomForestRegressor(random_state=seed)#default values + random_state = 13\n",
    "rf_regressor_leak.fit(X_train_leak, y_train_leak)\n",
    "\n",
    "\n",
    "leak_df = add_new_metrics(leak_df,\n",
    "                             rf_regressor_leak,\n",
    "                             X_train_leak,\n",
    "                             y_train_leak,\n",
    "                             split = \"train\",\n",
    "                             comments=\"with leakage.\")\n",
    "\n",
    "leak_df = add_new_metrics(leak_df,\n",
    "                             rf_regressor_leak,\n",
    "                             X_test_leak,\n",
    "                             y_test_leak,\n",
    "                             split = \"test\",\n",
    "                             comments=\"with leakage.\")\n",
    "\n",
    "leak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc7aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing for the test scores\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Ho: scores_leakage = scores_no_leakage \n",
    "# Ha: scores_leakage != scores_no_leakage  \n",
    "\n",
    "# Method 1: With leakage\n",
    "scores_leakage = cross_val_score(rf_regressor_leak, X_test_leak, y_test_leak, \n",
    "                                  cv=5, scoring='r2')\n",
    "\n",
    "# Method 2: Without leakage  \n",
    "scores_no_leakage = cross_val_score(rf_regressor, X_test, y_test,\n",
    "                                     cv=5, scoring='r2')\n",
    "\n",
    "# Paired t-test (same folds, so paired)\n",
    "t_stat, p_value = stats.ttest_rel(scores_leakage, scores_no_leakage)\n",
    "\n",
    "print(f\"Mean R² with leakage: {scores_leakage.mean():.4f} ± {scores_leakage.std():.4f}\")\n",
    "print(f\"Mean R² without leakage: {scores_no_leakage.mean():.4f} ± {scores_no_leakage.std():.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Difference is statistically significant. We reject the null hypothesis.\")\n",
    "else:\n",
    "    print(\"Difference is NOT statistically significant. We cannot reject the null hypothesis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3558b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing for the train scores\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Ho: scores_leakage = scores_no_leakage \n",
    "# Ha: scores_leakage != scores_no_leakage  \n",
    "\n",
    "# Method 1: With leakage\n",
    "scores_leakage = cross_val_score(rf_regressor_leak, X_train_leak, y_train_leak, \n",
    "                                  cv=5, scoring='r2')\n",
    "\n",
    "# Method 2: Without leakage  \n",
    "scores_no_leakage = cross_val_score(rf_regressor, X_train, y_train,\n",
    "                                     cv=5, scoring='r2')\n",
    "\n",
    "# Paired t-test (same folds, so paired)\n",
    "t_stat, p_value = stats.ttest_rel(scores_leakage, scores_no_leakage)\n",
    "\n",
    "print(f\"Mean R² with leakage: {scores_leakage.mean():.4f} ± {scores_leakage.std():.4f}\")\n",
    "print(f\"Mean R² without leakage: {scores_no_leakage.mean():.4f} ± {scores_no_leakage.std():.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Difference is statistically significant. We reject the null hypothesis.\")\n",
    "else:\n",
    "    print(\"Difference is NOT statistically significant. We cannot reject the null hypothesis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6ce58",
   "metadata": {},
   "source": [
    "## Statistical Significance Test: XGBoost Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5a78d7",
   "metadata": {},
   "source": [
    "### No leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5416909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBRegressor(seed = seed)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "leak_df = add_new_metrics(leak_df,\n",
    "                             xgb_clf,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             split = \"train\",\n",
    "                             comments=\"No leakage.\")\n",
    "\n",
    "leak_df = add_new_metrics(leak_df,\n",
    "                             xgb_clf,\n",
    "                             X_test,\n",
    "                             y_test,\n",
    "                             split = \"test\",\n",
    "                             comments=\"No leakage.\")\n",
    "\n",
    "leak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_leak = xgb.XGBRegressor(seed = seed)\n",
    "xgb_clf_leak.fit(X_train_leak, y_train_leak)\n",
    "\n",
    "leak_df = add_new_metrics(leak_df,\n",
    "                             xgb_clf_leak,\n",
    "                             X_train_leak,\n",
    "                             y_train_leak,\n",
    "                             split = \"train\",\n",
    "                             comments=\"with leakage.\")\n",
    "\n",
    "leak_df = add_new_metrics(leak_df,\n",
    "                             xgb_clf_leak,\n",
    "                             X_test_leak,\n",
    "                             y_test_leak,\n",
    "                             split = \"test\",\n",
    "                             comments=\"with leakage.\")\n",
    "\n",
    "leak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing for the test scores\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Ho: scores_leakage = scores_no_leakage \n",
    "# Ha: scores_leakage != scores_no_leakage  \n",
    "\n",
    "# Method 1: With leakage\n",
    "scores_leakage = cross_val_score(xgb_clf_leak, X_test_leak, y_test_leak, \n",
    "                                  cv=5, scoring='r2')\n",
    "\n",
    "# Method 2: Without leakage  \n",
    "scores_no_leakage = cross_val_score(xgb_clf, X_test, y_test,\n",
    "                                     cv=5, scoring='r2')\n",
    "\n",
    "# Paired t-test (same folds, so paired)\n",
    "t_stat, p_value = stats.ttest_rel(scores_leakage, scores_no_leakage)\n",
    "\n",
    "print(f\"Mean R² with leakage: {scores_leakage.mean():.4f} ± {scores_leakage.std():.4f}\")\n",
    "print(f\"Mean R² without leakage: {scores_no_leakage.mean():.4f} ± {scores_no_leakage.std():.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Difference is statistically significant. We reject the null hypothesis.\")\n",
    "else:\n",
    "    print(\"Difference is NOT statistically significant. We cannot reject the null hypothesis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing for the train scores\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Ho: scores_leakage = scores_no_leakage \n",
    "# Ha: scores_leakage != scores_no_leakage  \n",
    "\n",
    "# Method 1: With leakage\n",
    "scores_leakage = cross_val_score(xgb_clf_leak, X_train_leak, y_train_leak, \n",
    "                                  cv=5, scoring='r2')\n",
    "\n",
    "# Method 2: Without leakage  \n",
    "scores_no_leakage = cross_val_score(xgb_clf, X_train, y_train,\n",
    "                                     cv=5, scoring='r2')\n",
    "\n",
    "# Paired t-test (same folds, so paired)\n",
    "t_stat, p_value = stats.ttest_rel(scores_leakage, scores_no_leakage)\n",
    "\n",
    "print(f\"Mean R² with leakage: {scores_leakage.mean():.4f} ± {scores_leakage.std():.4f}\")\n",
    "print(f\"Mean R² without leakage: {scores_no_leakage.mean():.4f} ± {scores_no_leakage.std():.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Difference is statistically significant. We reject the null hypothesis.\")\n",
    "else:\n",
    "    print(\"Difference is NOT statistically significant. We cannot reject the null hypothesis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a136f5",
   "metadata": {},
   "source": [
    "## Conclusion on Leakage\n",
    "\n",
    "Statistical testing showed no significant difference between the approaches. For the scope of this analysis, we will proceed with the current implementation for simplicity, while acknowledging that a production-grade deployment would require the leakage-free pipeline to ensure strict data isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1fec41",
   "metadata": {},
   "source": [
    "## Export Dataset and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d139b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename_metrics = \"Metrics/outlier_analysis_metrics.csv\"\n",
    "\n",
    "# metrics_df.to_csv(filename_metrics, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename_data = \"Data/v1_house_sales.csv\"\n",
    "\n",
    "# df_clean.to_csv(filename_data, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "King-County-Housing-Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
